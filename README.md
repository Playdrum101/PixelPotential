
# Hybrid Quantum-Classical Image Classification using Quanvolution

![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg) 
## Project Overview

This repository contains the code and findings for a coursework project exploring the application of hybrid Quantum Machine Learning (QML) techniques for image classification. Specifically, it implements a "Quanvolutional" layer using PennyLane to extract features from images, which are then classified by a classical Keras neural network.

The project focuses on a binary classification task using a dataset of images representing Autistic vs. Non-Autistic subjects (preprocessed to 28x28 grayscale). The primary goal is to compare the performance (accuracy and loss) of this hybrid quantum-classical model against an identical classical neural network trained directly on the preprocessed image data.

## Key Features

* **Data Preprocessing:** Loads, standardizes (28x28 grayscale, normalized), and splits the image dataset.
* **Quantum Feature Extraction:** Implements a 4-qubit "Quanvolution" layer using PennyLane (`default.qubit` simulator) with fixed random parameters (`RandomLayers`) and angle encoding (`qml.RY`). Transforms (28x28x1) images into (14x14x4) feature maps.
* **Hybrid Model (`q_model`):** A Keras Sequential model (Flatten -> Dense) trained on the quantum feature maps.
* **Classical Baseline Model (`c_model`):** An identical Keras Sequential model trained directly on the preprocessed classical images.
* **Comparative Analysis:** Trains both models and generates plots comparing their validation accuracy and loss over epochs.
* **Visualization:** Includes code to visualize sample input images and the corresponding multi-channel quantum feature maps.

## Technology Stack

* **Programming Language:** Python 3
* **Quantum Computing:** PennyLane
* **Machine Learning:** TensorFlow, Keras
* **Numerical Computation:** NumPy
* **Data Handling/Splitting:** Scikit-learn
* **Image Handling:** Pillow (PIL)
* **Plotting:** Matplotlib

##  High-Level System Architecture Diagram
![SystemArchitecture](https://github.com/user-attachments/assets/12a37985-d9bb-492c-b522-50877ca8bfed)

## Dataset

* The project utilizes a dataset consisting of images categorized into 'Autistic' and 'Non_Autistic' classes.
* Images are preprocessed into 28x28 grayscale format for this experiment.

## Setup and Installation

1.  **Clone the repository:**
    ```bash
    git clone [https://github.com/](https://github.com/)[YourUsername]/[YourRepoName].git
    cd [YourRepoName]
    ```
2.  **Create a virtual environment (recommended):**
    ```bash
    python -m venv venv
    source venv/bin/activate  # On Windows use `venv\Scripts\activate`
    ```
3.  **Install dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
    *(You'll need to create a `requirements.txt` file listing the necessary libraries and versions, e.g., `pennylane`, `tensorflow`, `numpy`, `matplotlib`, `scikit-learn`, `Pillow`)*

4.  **Dataset:** Ensure the image dataset is placed in a directory structure expected by the code (e.g., a root folder containing 'Autistic' and 'Non_Autistic' subfolders). Update the `dataset_path` variable in the code if necessary.

## Usage

The primary workflow is contained within the Jupyter Notebook.

1.  Open and run the notebook/script cell by cell or execute the script.
2.  **Data Loading & Preprocessing:** The initial cells handle loading and preparing the data.
3.  **Quanvolution:** The quantum circuit is defined, and the `quanv` function processes the training and test images to generate quantum feature maps (`q_train_images`, `q_test_images`). *Note: This step can be computationally intensive.*
4.  **Model Definition:** The `MyModel` function defines the Keras classifier.
5.  **Training:** Separate cells/sections train the hybrid model (`q_model` on quantum features) and the classical baseline (`c_model` on classical images).
6.  **Results & Visualization:** Subsequent cells generate the comparison plots for validation accuracy and loss, and optionally visualize sample feature maps.

## Results Summary

The comparison plots generated by the script show the validation performance over 30 epochs:

* **Accuracy:** The hybrid model (`q_model`) using quantum features demonstrated consistently higher validation accuracy compared to the classical baseline (`c_model`).
* **Loss:** The hybrid model maintained a lower and more stable validation loss, while the classical baseline showed higher and slightly increasing loss, potentially indicating overfitting or difficulty fitting the data with the simple backend.


![image](https://github.com/user-attachments/assets/24410af2-cf3e-4bfd-a331-bb35787dc259)

![image](https://github.com/user-attachments/assets/0396d2dc-d97a-4deb-8e2b-901790df917d)



These results suggest that for this specific experimental setup, the quantum feature extraction provided a more effective representation for the simple classical classifier compared to using raw pixel data.
Limitations
Fixed Quantum Circuit: The quanvolution layer used fixed, non-optimized random parameters. Performance might differ with trainable or different circuit structures.
Baseline: Comparison was against an equally simple classical model, not state-of-the-art classical CNNs.
Simulation: Results are based on ideal quantum simulation; real hardware noise is not considered.
Scalability: Tested only on low-resolution (28x28) images.
Future Work
Implement and train variational quantum circuits within the quanvolution layer.
Use more appropriate binary classification backends (e.g., sigmoid activation, binary crossentropy).
Benchmark against standard classical CNN architectures.
Explore different quantum encoding methods.
Test scalability on larger datasets and higher-resolution images.
Investigate noise models or execution on real quantum hardware (if available).
